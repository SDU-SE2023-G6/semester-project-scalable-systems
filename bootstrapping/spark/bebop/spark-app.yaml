apiVersion: spark.stackable.tech/v1alpha1
kind: SparkApplication
metadata:
  name: pyspark-btctweet
spec:
  version: "1.0"
  sparkImage: docker.stackable.tech/demos/pyspark-k8s-with-kafka-and-iceberg:3.3.0-stackable23.4
  mode: cluster
  mainApplicationFile: "s3a://spark-data/spark-app.py"
  logFileDirectory:
    s3:
      prefix: eventlogs/
      bucket:
        reference: spark-history
  s3connection:
    reference: data-connection
  sparkConf:
    spark.hadoop.fs.s3a.aws.credentials.provider: "org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider"
    spark.hadoop.fs.s3a.endpoint: "http://minio:9000"
    spark.jars: |
      s3a://spark-data/jars/spark-sql-kafka-0-10_2.12-3.2.0.jar,
      s3a://spark-data/jars/spark-streaming-kafka-0-10_2.12-3.2.0.jar,
      s3a://spark-data/jars/kafka-clients-3.2.0.jar,
      s3a://spark-data/jars/spark-token-provider-kafka-0-10_2.12-3.2.0.jar,
      s3a://spark-data/jars/commons-pool2-2.8.0.jar
    kafkaAdress: "strimzi-kafka-bootstrap.kafka:9092"
    checkpointSentiment: "s3a://spark-data/cp_sentiment"
    checkpointTweetAgg: "s3a://spark-data/cp_agg_tweet"
    checkpointBtcAgg: "s3a://spark-data/cp_agg_btc"
    spark.kubernetes.driver.request.cores: "100m"
    spark.kubernetes.executor.request.cores: "100m"
    spark.kubernetes.driver.limit.cores: "300m"
    spark.kubernetes.executor.limit.cores: "400m"
    spark.kubernetes.driver.request.memory: "1Gi"
    spark.kubernetes.executor.request.memory: "1Gi"
    spark.kubernetes.driver.limit.memory: "1Gi"
    spark.kubernetes.executor.limit.memory: "1Gi"
  driver:
    resources:
      cpu:
        min: "50m"
        max: "200m"
      memory:
        limit: "1Gi"
  executor:
    instances: 4
    resources:
      cpu:
        min: "50m"
        max: "400m"
      memory:
        limit: "1Gi"
